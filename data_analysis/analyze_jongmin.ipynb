{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bb64503",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import seaborn as sns\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "from modules import optimize_null, forward_simulation, construct_null_trajectory\n",
    "from modules.elbo import ELBO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8fb763d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load behavioral data for erratic and smooth videos from AXB task\n",
    "f_path = '../data/jongmin_data/'\n",
    "\n",
    "n_corr_obs_erratic = pd.read_csv(Path(f_path) / 'nErratic.csv', header=None).to_numpy()\n",
    "n_total_obs_erratic = pd.read_csv(Path(f_path) / 'mErratic.csv', header=None).to_numpy()\n",
    "\n",
    "n_corr_obs_smooth = pd.read_csv(Path(f_path) / 'nSmooth.csv', header=None).to_numpy()\n",
    "n_total_obs_smooth = pd.read_csv(Path(f_path) / 'mSmooth.csv', header=None).to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0558714",
   "metadata": {},
   "source": [
    "### Estimate curvature for erratic videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "5b9a4112",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running MLE to initialize posterior..........................\n",
      "Current loss: 958.7406005859375\n",
      "Loss updated\n",
      "Iteration 1 | Loss: 958.7406005859375\n",
      "Current loss: 775.6856689453125\n",
      "Loss updated\n",
      "Iteration 2 | Loss: 775.6856689453125\n",
      "Current loss: 824.144775390625\n",
      "Iteration 3 | Loss: 824.144775390625\n",
      "Current loss: 789.619873046875\n",
      "Iteration 4 | Loss: 789.619873046875\n",
      "Current loss: 790.868408203125\n",
      "Iteration 5 | Loss: 790.868408203125\n",
      "Current loss: 920.6142578125\n",
      "Iteration 6 | Loss: 920.6142578125\n",
      "Current loss: 935.5322265625\n",
      "Iteration 7 | Loss: 935.5322265625\n",
      "Current loss: 903.9589233398438\n",
      "Iteration 8 | Loss: 903.9589233398438\n",
      "Current loss: 940.296630859375\n",
      "Iteration 9 | Loss: 940.296630859375\n",
      "Current loss: 805.6762084960938\n",
      "Iteration 10 | Loss: 805.6762084960938\n",
      "Epoch: 0, Loss: 3415.8214136868914\n",
      "Epoch: 250, Loss: 2072.6606587186734\n",
      "Epoch: 500, Loss: 1680.5937510501124\n",
      "Epoch: 750, Loss: 1476.6648920226908\n",
      "Epoch: 1000, Loss: 1341.7462733943678\n",
      "Epoch: 1250, Loss: 1236.6241849631458\n",
      "Epoch: 1500, Loss: 1178.6551751683064\n",
      "Epoch: 1750, Loss: 1122.0181015498124\n",
      "Epoch: 2000, Loss: 1081.6264186959636\n",
      "Epoch: 2250, Loss: 1034.9805564337166\n",
      "Epoch: 2500, Loss: 1001.9927709307831\n",
      "Epoch: 2750, Loss: 977.3878972649611\n",
      "Epoch: 3000, Loss: 951.3048131037186\n",
      "Epoch: 3250, Loss: 932.9297057137628\n",
      "Epoch: 3500, Loss: 908.879286843566\n",
      "Epoch: 3750, Loss: 887.0664011442557\n",
      "Epoch: 4000, Loss: 877.7654005582633\n",
      "Epoch: 4250, Loss: 862.3516156927552\n",
      "Epoch: 4500, Loss: 846.849051569739\n",
      "Epoch: 4750, Loss: 832.7981649911446\n",
      "Epoch: 5000, Loss: 822.4646912989186\n",
      "Epoch: 5250, Loss: 809.3703608665649\n",
      "Epoch: 5500, Loss: 803.2305211302864\n",
      "Epoch: 5750, Loss: 793.764720131093\n",
      "Epoch: 6000, Loss: 788.9068685606508\n",
      "Epoch: 6250, Loss: 777.942551993373\n",
      "Epoch: 6500, Loss: 772.9171964888903\n",
      "Epoch: 6750, Loss: 766.5088908314793\n",
      "Epoch: 7000, Loss: 759.3694422795838\n",
      "Epoch: 7250, Loss: 753.593957949107\n",
      "Epoch: 7500, Loss: 746.9855597599288\n",
      "Epoch: 7750, Loss: 745.6244878267776\n",
      "Epoch: 8000, Loss: 740.0344244780993\n",
      "Epoch: 8250, Loss: 735.8999144107996\n",
      "Epoch: 8500, Loss: 731.6432548212537\n",
      "Epoch: 8750, Loss: 730.1136887631453\n",
      "Epoch: 9000, Loss: 726.4706417486235\n",
      "Epoch: 9250, Loss: 722.7212426505255\n",
      "Epoch: 9500, Loss: 722.4014652385848\n",
      "Epoch: 9750, Loss: 717.6076813708028\n",
      "Epoch: 10000, Loss: 716.4610539108918\n",
      "Epoch: 10250, Loss: 714.8222179561765\n",
      "Epoch: 10500, Loss: 713.7853728220671\n",
      "Epoch: 10750, Loss: 712.0916855573009\n",
      "Epoch: 11000, Loss: 708.9653125877319\n",
      "Epoch: 11250, Loss: 707.8911197417577\n",
      "Epoch: 11500, Loss: 706.3760607154346\n",
      "Epoch: 11750, Loss: 705.52495954171\n",
      "Epoch: 12000, Loss: 705.2454333274778\n",
      "Epoch: 12250, Loss: 703.4772319365393\n",
      "Epoch: 12500, Loss: 703.177039112695\n",
      "Epoch: 12750, Loss: 702.5937286769841\n",
      "Epoch: 13000, Loss: 701.4294736560687\n",
      "Epoch: 13250, Loss: 700.3650202124538\n",
      "Epoch: 13500, Loss: 699.6749871147217\n",
      "Epoch: 13750, Loss: 698.8557143306399\n",
      "Epoch: 14000, Loss: 698.7422755202291\n",
      "Epoch: 14250, Loss: 698.7464564549281\n",
      "Epoch: 14500, Loss: 696.2470768879417\n",
      "Epoch: 14750, Loss: 696.2667377782268\n",
      "Epoch: 15000, Loss: 694.6173726008477\n",
      "Epoch: 15250, Loss: 695.375056917236\n",
      "Epoch: 15500, Loss: 694.2325556215874\n",
      "Epoch: 15750, Loss: 693.7819005064863\n",
      "Epoch: 16000, Loss: 693.5788821900129\n",
      "Epoch: 16250, Loss: 692.9434731964064\n",
      "Epoch: 16500, Loss: 693.2304270323028\n",
      "Epoch: 16750, Loss: 693.20693936502\n",
      "Epoch: 17000, Loss: 693.2091554587367\n",
      "Epoch: 17250, Loss: 691.4413915415435\n",
      "Epoch: 17500, Loss: 691.5614302472907\n",
      "Epoch: 17750, Loss: 690.9490491545088\n",
      "Epoch: 18000, Loss: 691.4457919427792\n",
      "Epoch: 18250, Loss: 689.8042148219916\n",
      "Epoch: 18500, Loss: 690.874970389515\n",
      "Epoch: 18750, Loss: 689.9435073934559\n",
      "Epoch: 19000, Loss: 691.6534368801958\n",
      "Epoch: 19250, Loss: 688.8388233605634\n",
      "Epoch: 19500, Loss: 689.9488653488711\n",
      "Epoch: 19750, Loss: 688.9024852005133\n",
      "Epoch: 20000, Loss: 689.3146747861356\n",
      "Epoch: 20250, Loss: 689.1434737045377\n",
      "Epoch: 20500, Loss: 688.4711768685312\n",
      "Epoch: 20750, Loss: 688.4516808366978\n",
      "Epoch: 21000, Loss: 689.2809344320455\n",
      "Epoch: 21250, Loss: 688.0441571435451\n",
      "Epoch: 21500, Loss: 688.3337879374106\n",
      "Epoch: 21750, Loss: 687.4094676029813\n",
      "Epoch: 22000, Loss: 688.979790854969\n",
      "Epoch: 22250, Loss: 688.6313298645379\n",
      "Epoch: 22500, Loss: 686.1000725685441\n",
      "Epoch: 22750, Loss: 686.18679947994\n",
      "Epoch: 23000, Loss: 687.2171860420168\n",
      "Epoch: 23250, Loss: 687.2675471391007\n",
      "Epoch: 23500, Loss: 686.4708900477801\n",
      "Epoch: 23750, Loss: 686.7431143395264\n",
      "Epoch: 24000, Loss: 686.7064224337961\n",
      "Epoch: 24250, Loss: 686.1523376905452\n",
      "Epoch: 24500, Loss: 686.4471768113752\n",
      "Epoch: 24750, Loss: 686.1159211047893\n",
      "Epoch: 25000, Loss: 685.6786696547114\n",
      "Epoch: 25250, Loss: 684.7922068811783\n",
      "Epoch: 25500, Loss: 684.3235948953052\n",
      "Epoch: 25750, Loss: 686.1807415036894\n",
      "Epoch: 26000, Loss: 685.4566810398198\n",
      "Epoch: 26250, Loss: 685.247354984089\n",
      "Epoch: 26500, Loss: 686.0309844085295\n",
      "Epoch: 26750, Loss: 685.2708301009769\n",
      "Epoch: 27000, Loss: 685.1141166980765\n",
      "Epoch: 27250, Loss: 685.539021110425\n",
      "Epoch: 27500, Loss: 684.6343828408889\n",
      "Epoch: 27750, Loss: 685.205587632869\n",
      "Epoch: 28000, Loss: 685.6626881508648\n",
      "Epoch: 28250, Loss: 685.8410905465446\n",
      "Epoch: 28500, Loss: 684.1906725953762\n",
      "Epoch: 28750, Loss: 685.2690154387171\n",
      "Epoch: 29000, Loss: 685.4724245400199\n",
      "Epoch: 29250, Loss: 685.0591736298123\n",
      "Epoch: 29500, Loss: 685.4278402736273\n",
      "Epoch: 29750, Loss: 685.4889395838187\n",
      "Epoch: 30000, Loss: 685.3377305502759\n",
      "Epoch: 30250, Loss: 684.913747031286\n",
      "Epoch: 30500, Loss: 685.639258874843\n",
      "Epoch: 30750, Loss: 684.798422674918\n",
      "Epoch: 31000, Loss: 685.1909218624969\n",
      "Epoch: 31250, Loss: 684.6068792787248\n",
      "Epoch: 31500, Loss: 684.0224885175165\n",
      "Epoch: 31750, Loss: 684.934188937464\n",
      "Epoch: 32000, Loss: 683.9390210622245\n",
      "Epoch: 32250, Loss: 684.825405518206\n",
      "Epoch: 32500, Loss: 686.4871995540519\n",
      "Epoch: 32750, Loss: 686.4202082060855\n",
      "Epoch: 33000, Loss: 685.949169719766\n",
      "Epoch: 33250, Loss: 684.4960506351798\n",
      "Epoch: 33500, Loss: 684.6264883724557\n",
      "Epoch: 33750, Loss: 684.1317365439885\n",
      "Epoch: 34000, Loss: 684.8185739641076\n",
      "Epoch: 34250, Loss: 685.8767081305565\n",
      "Epoch: 34500, Loss: 685.4534853146944\n",
      "Epoch: 34750, Loss: 684.8359088640034\n",
      "Epoch: 35000, Loss: 684.3597015384081\n",
      "Epoch: 35250, Loss: 684.5084933023712\n",
      "Epoch: 35500, Loss: 685.4878576629388\n",
      "Epoch: 35750, Loss: 686.0384218339542\n",
      "Epoch: 36000, Loss: 684.3490109676477\n",
      "Epoch: 36250, Loss: 685.1878009751601\n",
      "Epoch: 36500, Loss: 686.2581426936674\n",
      "Epoch: 36750, Loss: 684.1049970207079\n",
      "Epoch: 37000, Loss: 685.2921498234244\n",
      "Epoch: 37250, Loss: 684.4482772515382\n",
      "Epoch: 37500, Loss: 686.5728403511579\n",
      "Epoch: 37750, Loss: 683.713130492309\n",
      "Epoch: 38000, Loss: 684.7275919792074\n",
      "Epoch: 38250, Loss: 685.2641252822079\n",
      "Epoch: 38500, Loss: 684.4793232856053\n",
      "Epoch: 38750, Loss: 685.2258530843561\n",
      "Epoch: 39000, Loss: 684.6709248054848\n",
      "Epoch: 39250, Loss: 685.9264500890789\n",
      "Epoch: 39500, Loss: 685.6790307080258\n",
      "Epoch: 39750, Loss: 684.4353849631783\n",
      "Epoch: 40000, Loss: 685.3032616152115\n",
      "Epoch: 40250, Loss: 683.2799580011545\n",
      "Epoch: 40500, Loss: 684.5142460346365\n",
      "Epoch: 40750, Loss: 684.2728106655088\n",
      "Epoch: 41000, Loss: 684.3805474173657\n",
      "Epoch: 41250, Loss: 685.5659471927595\n",
      "Epoch: 41500, Loss: 684.1917942750393\n",
      "Epoch: 41750, Loss: 684.6599134829726\n",
      "Epoch: 42000, Loss: 684.6499329291852\n",
      "Epoch: 42250, Loss: 685.7710822926732\n",
      "Epoch: 42500, Loss: 683.6994395136052\n",
      "Epoch: 42750, Loss: 684.9743569848375\n",
      "Epoch: 43000, Loss: 684.4389010240602\n",
      "Epoch: 43250, Loss: 684.6508451557374\n",
      "Epoch: 43500, Loss: 685.3845084665325\n",
      "Epoch: 43750, Loss: 683.9832650396687\n",
      "Epoch: 44000, Loss: 685.1606116510571\n",
      "Epoch: 44250, Loss: 684.2781076555077\n",
      "Epoch: 44500, Loss: 684.8182154080797\n",
      "Epoch: 44750, Loss: 682.7240621175307\n",
      "Epoch: 45000, Loss: 684.6969272413951\n",
      "Epoch: 45250, Loss: 683.7682448722489\n",
      "Epoch: 45500, Loss: 685.2391733568506\n",
      "Epoch: 45750, Loss: 685.4762936138128\n",
      "Epoch: 46000, Loss: 684.1311965879296\n",
      "Epoch: 46250, Loss: 683.5935678685311\n",
      "Epoch: 46500, Loss: 684.4382751517379\n",
      "Epoch: 46750, Loss: 683.7551207032228\n",
      "Epoch: 47000, Loss: 685.1026124809549\n",
      "Epoch: 47250, Loss: 684.9043611115134\n",
      "Epoch: 47500, Loss: 686.0207109431799\n",
      "Epoch: 47750, Loss: 683.280585088898\n",
      "Epoch: 48000, Loss: 685.6581689921788\n",
      "Epoch: 48250, Loss: 684.898296788677\n",
      "Epoch: 48500, Loss: 684.9685398357993\n",
      "Epoch: 48750, Loss: 683.9974948033645\n",
      "Epoch: 49000, Loss: 684.3170240217732\n",
      "Epoch: 49250, Loss: 684.8518393353302\n",
      "Epoch: 49500, Loss: 685.4157918146433\n",
      "Epoch: 49750, Loss: 684.2853228581412\n",
      "Epoch: 50000, Loss: 684.4927361732092\n",
      "Epoch: 50250, Loss: 685.1440672747015\n",
      "Epoch: 50500, Loss: 683.8968360428571\n",
      "Epoch: 50750, Loss: 684.7393205181085\n",
      "Epoch: 51000, Loss: 684.5783713426248\n",
      "Epoch: 51250, Loss: 685.0135611577399\n",
      "Epoch: 51500, Loss: 683.7416827177748\n",
      "Epoch: 51750, Loss: 685.7597420766276\n",
      "Epoch: 52000, Loss: 684.3580351169448\n",
      "Epoch: 52250, Loss: 685.1096338030503\n",
      "Epoch: 52500, Loss: 684.8970658380657\n",
      "Epoch: 52750, Loss: 684.6312377157153\n",
      "Epoch: 53000, Loss: 684.8473533532734\n",
      "Epoch: 53250, Loss: 685.6051567016071\n",
      "Epoch: 53500, Loss: 683.8092102783212\n",
      "Epoch: 53750, Loss: 684.7758306430372\n",
      "Epoch: 54000, Loss: 684.8041794369838\n",
      "Epoch: 54250, Loss: 685.0559058176581\n",
      "Epoch: 54500, Loss: 684.4595946000852\n",
      "Epoch: 54750, Loss: 685.0273169871654\n",
      "Epoch: 55000, Loss: 684.2024304401905\n",
      "Epoch: 55250, Loss: 683.5118589288114\n",
      "Epoch: 55500, Loss: 685.0932471803446\n",
      "Epoch: 55750, Loss: 684.6348750341847\n",
      "Epoch: 56000, Loss: 684.1060160505873\n",
      "Epoch: 56250, Loss: 684.9442732289768\n",
      "Epoch: 56500, Loss: 684.2147324562693\n",
      "Epoch: 56750, Loss: 685.5538871240855\n",
      "Epoch: 57000, Loss: 684.4774308150099\n",
      "Epoch: 57250, Loss: 684.4918955029314\n",
      "Epoch: 57500, Loss: 685.301821426347\n",
      "Epoch: 57750, Loss: 685.1687169421754\n",
      "Epoch: 58000, Loss: 685.2642023914319\n",
      "Epoch: 58250, Loss: 684.4639682376433\n",
      "Epoch: 58500, Loss: 685.6745208516061\n",
      "Epoch: 58750, Loss: 684.6484208284202\n",
      "Epoch: 59000, Loss: 683.8764048023029\n",
      "Epoch: 59250, Loss: 684.1582132889366\n",
      "Epoch: 59500, Loss: 684.0322135225422\n",
      "Epoch: 59750, Loss: 686.295777459469\n"
     ]
    }
   ],
   "source": [
    "# estimate curvature for erratic video\n",
    "n_dim = 5\n",
    "elbo_erratic = ELBO(n_dim, n_corr_obs_erratic, n_total_obs_erratic, n_starts=10, n_iterations=60000)\n",
    "x_erratic, p_erratic, errors_erratic, kl_loss_erratic, ll_loss_erratic, c_prior_erratic, d_prior_erratic, l_prior_erratic, c_post_erratic, d_post_erratic, l_post_erratic, c_est_erratic = elbo.optimize_ELBO_SGD()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "e0455167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated global curvature (erratic): 76.16986083984375 degrees\n",
      "Average estimated local curvature from posterior (erratic): 76.17062890237396 degrees\n",
      "Average estimated local curvature from most likely trajectory (erratic): 76.17062377929688 degrees\n"
     ]
    }
   ],
   "source": [
    "est_global_curvature_erratic = torch.rad2deg(elbo_erratic.mu_prior_c.detach())\n",
    "print(f'Estimated global curvature (erratic): {est_global_curvature_erratic} degrees')\n",
    "print(f'Average estimated local curvature from posterior (erratic): {torch.rad2deg(torch.mean(elbo_erratic.mu_post_c).detach())} degrees')\n",
    "print(f'Average estimated local curvature from most likely trajectory (erratic): {torch.rad2deg(torch.mean(c_est_erratic).detach())} degrees')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "f64dcc1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEM estimated from curvature of most likely trajectory (erratic): 0.0034754432272166014\n",
      "SEM estimated from posterior (erratic): 0.0034754551567432665\n",
      "SEM estimated from prior (erratic): 0.07731721733869623\n"
     ]
    }
   ],
   "source": [
    "# compute standard error of the mean (SEM)\n",
    "sem_cest_erratic = torch.sqrt(torch.var(c_est_erratic) / c_est_erratic.shape[1])\n",
    "sem_post_erratic = torch.sqrt(torch.var(elbo_erratic.mu_post_c) / elbo_erratic.mu_post_c.shape[0])\n",
    "sem_prior_erratic = elbo_erratic.sigma_prior_c\n",
    "\n",
    "print(f'SEM estimated from curvature of most likely trajectory (erratic): {sem_cest_erratic}')\n",
    "print(f'SEM estimated from posterior (erratic): {sem_post_erratic}')\n",
    "print(f'SEM estimated from prior (erratic): {sem_prior_erratic.detach().numpy()[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d79ee1",
   "metadata": {},
   "source": [
    "### Estimate curvature for smooth videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "cfa945fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running MLE to initialize posterior..........................\n",
      "Current loss: 973.8453369140625\n",
      "Loss updated\n",
      "Iteration 1 | Loss: 973.8453369140625\n",
      "Current loss: 885.8164672851562\n",
      "Loss updated\n",
      "Iteration 2 | Loss: 885.8164672851562\n",
      "Current loss: 1041.803955078125\n",
      "Iteration 3 | Loss: 1041.803955078125\n",
      "Current loss: 925.2678833007812\n",
      "Iteration 4 | Loss: 925.2678833007812\n",
      "Current loss: 914.5169677734375\n",
      "Iteration 5 | Loss: 914.5169677734375\n",
      "Current loss: 948.547607421875\n",
      "Iteration 6 | Loss: 948.547607421875\n",
      "Current loss: 913.183349609375\n",
      "Iteration 7 | Loss: 913.183349609375\n",
      "Current loss: 942.5897827148438\n",
      "Iteration 8 | Loss: 942.5897827148438\n",
      "Current loss: 943.4119262695312\n",
      "Iteration 9 | Loss: 943.4119262695312\n",
      "Current loss: 917.407470703125\n",
      "Iteration 10 | Loss: 917.407470703125\n",
      "Epoch: 0, Loss: 8804.34472586646\n",
      "Epoch: 250, Loss: 3636.7629255686243\n",
      "Epoch: 500, Loss: 2637.3925784163052\n",
      "Epoch: 750, Loss: 2212.9377630261693\n",
      "Epoch: 1000, Loss: 1931.921828450646\n",
      "Epoch: 1250, Loss: 1757.376380814831\n",
      "Epoch: 1500, Loss: 1619.0425443362547\n",
      "Epoch: 1750, Loss: 1523.9598913939685\n",
      "Epoch: 2000, Loss: 1436.980180120685\n",
      "Epoch: 2250, Loss: 1373.393248777375\n",
      "Epoch: 2500, Loss: 1314.6445174665714\n",
      "Epoch: 2750, Loss: 1265.4025209030624\n",
      "Epoch: 3000, Loss: 1224.5044977714304\n",
      "Epoch: 3250, Loss: 1186.7373705639252\n",
      "Epoch: 3500, Loss: 1158.6967432650997\n",
      "Epoch: 3750, Loss: 1129.6234346884619\n",
      "Epoch: 4000, Loss: 1106.97857764822\n",
      "Epoch: 4250, Loss: 1079.5863850526007\n",
      "Epoch: 4500, Loss: 1057.7736765722107\n",
      "Epoch: 4750, Loss: 1042.1085953048018\n",
      "Epoch: 5000, Loss: 1026.239522983325\n",
      "Epoch: 5250, Loss: 1010.15169866574\n",
      "Epoch: 5500, Loss: 993.9536475460256\n",
      "Epoch: 5750, Loss: 982.4167827722982\n",
      "Epoch: 6000, Loss: 969.2123592158249\n",
      "Epoch: 6250, Loss: 958.1775160253897\n",
      "Epoch: 6500, Loss: 947.8018146333179\n",
      "Epoch: 6750, Loss: 938.6033048533424\n",
      "Epoch: 7000, Loss: 931.2267365337054\n",
      "Epoch: 7250, Loss: 922.4209509047348\n",
      "Epoch: 7500, Loss: 917.0873356065953\n",
      "Epoch: 7750, Loss: 907.8630809778657\n",
      "Epoch: 8000, Loss: 903.1554882859105\n",
      "Epoch: 8250, Loss: 898.367607441214\n",
      "Epoch: 8500, Loss: 893.5026654310013\n",
      "Epoch: 8750, Loss: 888.9883466221224\n",
      "Epoch: 9000, Loss: 883.8602910917998\n",
      "Epoch: 9250, Loss: 879.9492665725091\n",
      "Epoch: 9500, Loss: 876.953253102453\n",
      "Epoch: 9750, Loss: 873.4047142788811\n",
      "Epoch: 10000, Loss: 871.0818029211838\n",
      "Epoch: 10250, Loss: 867.9462716452202\n",
      "Epoch: 10500, Loss: 866.4528219311424\n",
      "Epoch: 10750, Loss: 863.8117296914312\n",
      "Epoch: 11000, Loss: 862.5308076007777\n",
      "Epoch: 11250, Loss: 860.9915912538912\n",
      "Epoch: 11500, Loss: 859.1073015772873\n",
      "Epoch: 11750, Loss: 858.6377791657281\n",
      "Epoch: 12000, Loss: 857.0335229224379\n",
      "Epoch: 12250, Loss: 856.2045079477576\n",
      "Epoch: 12500, Loss: 855.6743771831393\n",
      "Epoch: 12750, Loss: 854.6884494826023\n",
      "Epoch: 13000, Loss: 854.15403071688\n",
      "Epoch: 13250, Loss: 853.3694223294281\n",
      "Epoch: 13500, Loss: 853.4000885323798\n",
      "Epoch: 13750, Loss: 852.5202973309115\n",
      "Epoch: 14000, Loss: 852.655012487958\n",
      "Epoch: 14250, Loss: 852.5090525111639\n",
      "Epoch: 14500, Loss: 851.7742391249919\n",
      "Epoch: 14750, Loss: 852.5082460172105\n",
      "Epoch: 15000, Loss: 851.8012698265164\n",
      "Epoch: 15250, Loss: 851.4567808049408\n",
      "Epoch: 15500, Loss: 852.4228316957006\n",
      "Epoch: 15750, Loss: 851.425759983117\n",
      "Epoch: 16000, Loss: 851.541544679464\n",
      "Epoch: 16250, Loss: 850.6652884265682\n",
      "Epoch: 16500, Loss: 851.9859020501665\n",
      "Epoch: 16750, Loss: 851.3817087209777\n",
      "Epoch: 17000, Loss: 850.9410842720195\n",
      "Epoch: 17250, Loss: 851.0238549282335\n",
      "Epoch: 17500, Loss: 850.5500505764361\n",
      "Epoch: 17750, Loss: 850.6651850848992\n",
      "Epoch: 18000, Loss: 850.6538690661683\n",
      "Epoch: 18250, Loss: 850.3879971598527\n",
      "Epoch: 18500, Loss: 850.4744295355772\n",
      "Epoch: 18750, Loss: 850.5864719337314\n",
      "Epoch: 19000, Loss: 850.469180888061\n",
      "Epoch: 19250, Loss: 850.6726080369535\n",
      "Epoch: 19500, Loss: 849.9345385322414\n",
      "Epoch: 19750, Loss: 850.9971871273664\n",
      "Epoch: 20000, Loss: 850.5788072864332\n",
      "Epoch: 20250, Loss: 850.4506271071225\n",
      "Epoch: 20500, Loss: 850.4027693108034\n",
      "Epoch: 20750, Loss: 849.7860248860596\n",
      "Epoch: 21000, Loss: 850.478611575647\n",
      "Epoch: 21250, Loss: 849.9794620470814\n",
      "Epoch: 21500, Loss: 850.6383085257995\n",
      "Epoch: 21750, Loss: 850.1993066007857\n",
      "Epoch: 22000, Loss: 849.867684239338\n",
      "Epoch: 22250, Loss: 850.3487920093099\n",
      "Epoch: 22500, Loss: 849.8801082147731\n",
      "Epoch: 22750, Loss: 850.1825323533174\n",
      "Epoch: 23000, Loss: 849.394761966648\n",
      "Epoch: 23250, Loss: 850.2111534097114\n",
      "Epoch: 23500, Loss: 849.8574381890865\n",
      "Epoch: 23750, Loss: 849.7710666418919\n",
      "Epoch: 24000, Loss: 850.5086177131511\n",
      "Epoch: 24250, Loss: 849.7264672546913\n",
      "Epoch: 24500, Loss: 850.7441778701245\n",
      "Epoch: 24750, Loss: 849.8946716981728\n",
      "Epoch: 25000, Loss: 850.0886108907403\n",
      "Epoch: 25250, Loss: 849.3932147173456\n",
      "Epoch: 25500, Loss: 849.5520014347362\n",
      "Epoch: 25750, Loss: 849.9100042132403\n",
      "Epoch: 26000, Loss: 848.9135190641395\n",
      "Epoch: 26250, Loss: 849.5417973103808\n",
      "Epoch: 26500, Loss: 849.7242399422964\n",
      "Epoch: 26750, Loss: 849.3683405391579\n",
      "Epoch: 27000, Loss: 849.9016419941393\n",
      "Epoch: 27250, Loss: 849.7077826546428\n",
      "Epoch: 27500, Loss: 849.8922930715131\n",
      "Epoch: 27750, Loss: 848.964195156379\n",
      "Epoch: 28000, Loss: 849.1355149328665\n",
      "Epoch: 28250, Loss: 849.3057807877004\n",
      "Epoch: 28500, Loss: 849.8761504077157\n",
      "Epoch: 28750, Loss: 849.206927706151\n",
      "Epoch: 29000, Loss: 850.6543512106083\n",
      "Epoch: 29250, Loss: 849.6959235548532\n",
      "Epoch: 29500, Loss: 848.8562044034223\n",
      "Epoch: 29750, Loss: 849.3369100661977\n",
      "Epoch: 30000, Loss: 849.9914022910418\n",
      "Epoch: 30250, Loss: 849.4704586012454\n",
      "Epoch: 30500, Loss: 849.4447237313353\n",
      "Epoch: 30750, Loss: 849.5543266807252\n",
      "Epoch: 31000, Loss: 849.1888147457097\n",
      "Epoch: 31250, Loss: 850.0195547455579\n",
      "Epoch: 31500, Loss: 849.8412589162572\n",
      "Epoch: 31750, Loss: 849.5947697061698\n",
      "Epoch: 32000, Loss: 848.8132885805151\n",
      "Epoch: 32250, Loss: 849.5013654843895\n",
      "Epoch: 32500, Loss: 849.8415512887009\n",
      "Epoch: 32750, Loss: 849.5074554573317\n",
      "Epoch: 33000, Loss: 849.5557353874782\n",
      "Epoch: 33250, Loss: 849.8050260341872\n",
      "Epoch: 33500, Loss: 849.186224029708\n",
      "Epoch: 33750, Loss: 849.4481173170614\n",
      "Epoch: 34000, Loss: 850.0252582581536\n",
      "Epoch: 34250, Loss: 849.7930864780304\n",
      "Epoch: 34500, Loss: 848.8335970874874\n",
      "Epoch: 34750, Loss: 849.5410571371929\n",
      "Epoch: 35000, Loss: 849.6836141039743\n",
      "Epoch: 35250, Loss: 849.2431459585454\n",
      "Epoch: 35500, Loss: 849.1292346627405\n",
      "Epoch: 35750, Loss: 849.7369007666753\n",
      "Epoch: 36000, Loss: 848.8465576537951\n",
      "Epoch: 36250, Loss: 849.8955254456754\n",
      "Epoch: 36500, Loss: 849.4771201861801\n",
      "Epoch: 36750, Loss: 849.0663831321258\n",
      "Epoch: 37000, Loss: 848.9881769528301\n",
      "Epoch: 37250, Loss: 849.6172606140212\n",
      "Epoch: 37500, Loss: 848.8736518737052\n",
      "Epoch: 37750, Loss: 850.0622835010172\n",
      "Epoch: 38000, Loss: 850.2197015096974\n",
      "Epoch: 38250, Loss: 850.2235110348938\n",
      "Epoch: 38500, Loss: 849.3315860921534\n",
      "Epoch: 38750, Loss: 849.800427434061\n",
      "Epoch: 39000, Loss: 849.6721007984495\n",
      "Epoch: 39250, Loss: 849.5463173802885\n",
      "Epoch: 39500, Loss: 849.4989774776775\n",
      "Epoch: 39750, Loss: 849.8352052944604\n",
      "Epoch: 40000, Loss: 849.2430620721036\n",
      "Epoch: 40250, Loss: 849.0958880003666\n",
      "Epoch: 40500, Loss: 849.6784832518531\n",
      "Epoch: 40750, Loss: 849.674633000992\n",
      "Epoch: 41000, Loss: 849.2054963718987\n",
      "Epoch: 41250, Loss: 850.1504586795978\n",
      "Epoch: 41500, Loss: 849.1660198437289\n",
      "Epoch: 41750, Loss: 849.6118659459023\n",
      "Epoch: 42000, Loss: 849.2366850206466\n",
      "Epoch: 42250, Loss: 849.2883144971472\n",
      "Epoch: 42500, Loss: 848.8819513929218\n",
      "Epoch: 42750, Loss: 849.607904717844\n",
      "Epoch: 43000, Loss: 849.306877905687\n",
      "Epoch: 43250, Loss: 849.1086292649101\n",
      "Epoch: 43500, Loss: 848.9297807310012\n",
      "Epoch: 43750, Loss: 849.2996114101577\n",
      "Epoch: 44000, Loss: 849.1670590065902\n",
      "Epoch: 44250, Loss: 849.8357031525974\n",
      "Epoch: 44500, Loss: 849.3244457906388\n",
      "Epoch: 44750, Loss: 849.8218515394216\n",
      "Epoch: 45000, Loss: 849.0068601483699\n",
      "Epoch: 45250, Loss: 849.1586258661308\n",
      "Epoch: 45500, Loss: 849.0986230398275\n",
      "Epoch: 45750, Loss: 849.1546373440655\n",
      "Epoch: 46000, Loss: 849.2879879914141\n",
      "Epoch: 46250, Loss: 848.8969147147731\n",
      "Epoch: 46500, Loss: 849.9963068857996\n",
      "Epoch: 46750, Loss: 849.5519569367243\n",
      "Epoch: 47000, Loss: 849.3264154531417\n",
      "Epoch: 47250, Loss: 849.9114472004295\n",
      "Epoch: 47500, Loss: 849.6851169148171\n",
      "Epoch: 47750, Loss: 849.0637676653638\n",
      "Epoch: 48000, Loss: 849.9387463989889\n",
      "Epoch: 48250, Loss: 848.161549274286\n",
      "Epoch: 48500, Loss: 849.37876075703\n",
      "Epoch: 48750, Loss: 849.02607180309\n",
      "Epoch: 49000, Loss: 849.1204113066451\n",
      "Epoch: 49250, Loss: 849.5108234639699\n",
      "Epoch: 49500, Loss: 849.4160089020063\n",
      "Epoch: 49750, Loss: 849.3193313630915\n",
      "Epoch: 50000, Loss: 849.9816276847708\n",
      "Epoch: 50250, Loss: 849.4927978125836\n",
      "Epoch: 50500, Loss: 849.3621295000199\n",
      "Epoch: 50750, Loss: 849.2513326230322\n",
      "Epoch: 51000, Loss: 849.3860281597256\n",
      "Epoch: 51250, Loss: 849.2252895383181\n",
      "Epoch: 51500, Loss: 849.0659253121299\n",
      "Epoch: 51750, Loss: 850.0657962857474\n",
      "Epoch: 52000, Loss: 849.5696492008527\n",
      "Epoch: 52250, Loss: 849.2928475274339\n",
      "Epoch: 52500, Loss: 849.6568455255839\n",
      "Epoch: 52750, Loss: 849.7333988021988\n",
      "Epoch: 53000, Loss: 849.3921398648258\n",
      "Epoch: 53250, Loss: 848.949775102407\n",
      "Epoch: 53500, Loss: 849.6763619275295\n",
      "Epoch: 53750, Loss: 849.0662017316539\n",
      "Epoch: 54000, Loss: 849.8375923573839\n",
      "Epoch: 54250, Loss: 848.8423388299988\n",
      "Epoch: 54500, Loss: 849.0883985207663\n",
      "Epoch: 54750, Loss: 848.9129843148962\n",
      "Epoch: 55000, Loss: 849.190459542745\n",
      "Epoch: 55250, Loss: 849.700663714425\n",
      "Epoch: 55500, Loss: 849.5026785958233\n",
      "Epoch: 55750, Loss: 849.7161073701901\n",
      "Epoch: 56000, Loss: 849.7375081180685\n",
      "Epoch: 56250, Loss: 848.9023951742033\n",
      "Epoch: 56500, Loss: 850.1393454500319\n",
      "Epoch: 56750, Loss: 849.2264164727394\n",
      "Epoch: 57000, Loss: 849.5476565420059\n",
      "Epoch: 57250, Loss: 849.3229703692873\n",
      "Epoch: 57500, Loss: 848.6955431054535\n",
      "Epoch: 57750, Loss: 849.4162084001237\n",
      "Epoch: 58000, Loss: 849.4453596177558\n",
      "Epoch: 58250, Loss: 849.1177202310614\n",
      "Epoch: 58500, Loss: 849.5342451027487\n",
      "Epoch: 58750, Loss: 849.8521815758461\n",
      "Epoch: 59000, Loss: 849.3326550261215\n",
      "Epoch: 59250, Loss: 849.3424745033067\n",
      "Epoch: 59500, Loss: 848.4317853118772\n",
      "Epoch: 59750, Loss: 849.4073437694924\n"
     ]
    }
   ],
   "source": [
    "# estimate curvature for smooth video\n",
    "n_dim = 5\n",
    "elbo_smooth = ELBO(n_dim, n_corr_obs_smooth, n_total_obs_smooth, n_starts=10, n_iterations=60000)\n",
    "x_smooth, p_smooth, errors_smooth, kl_loss_smooth, ll_loss_smooth, c_prior_smooth, d_prior_smooth, l_prior_smooth, c_post_smooth, d_post_smooth, l_post_smooth, c_est_smooth = elbo_smooth.optimize_ELBO_SGD()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "697adf67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estimated global curvature (smooth): 48.2387809753418 degrees\n",
      "Average estimated local curvature from posterior (smooth): 48.24112972777927 degrees\n",
      "Average estimated local curvature from most likely trajectory (smooth): 48.24113464355469 degrees\n"
     ]
    }
   ],
   "source": [
    "est_global_curvature_smooth = torch.rad2deg(elbo_smooth.mu_prior_c.detach())\n",
    "print(f'Estimated global curvature (smooth): {est_global_curvature_smooth} degrees')\n",
    "print(f'Average estimated local curvature from posterior (smooth): {torch.rad2deg(torch.mean(elbo_smooth.mu_post_c).detach())} degrees')\n",
    "print(f'Average estimated local curvature from most likely trajectory (smooth): {torch.rad2deg(torch.mean(c_est_smooth).detach())} degrees')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "fda644b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SEM estimated from curvature of most likely trajectory (smooth): 0.06210042163729668\n",
      "SEM estimated from posterior (smooth): 0.06210041081173285\n",
      "SEM estimated from prior (smooth): 0.3323638423112401\n"
     ]
    }
   ],
   "source": [
    "# compute standard error of the mean (SEM)\n",
    "sem_cest_smooth = torch.sqrt(torch.var(c_est_smooth) / c_est_smooth.shape[1])\n",
    "sem_post_smooth = torch.sqrt(torch.var(elbo_smooth.mu_post_c) / elbo_smooth.mu_post_c.shape[0])\n",
    "sem_prior_smooth = elbo_smooth.sigma_prior_c\n",
    "\n",
    "print(f'SEM estimated from curvature of most likely trajectory (smooth): {sem_cest_smooth}')\n",
    "print(f'SEM estimated from posterior (smooth): {sem_post_smooth}')\n",
    "print(f'SEM estimated from prior (smooth): {sem_prior_smooth.detach().numpy()[0]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd99265a",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
