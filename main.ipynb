{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0eb893b7-c46c-48e4-93d9-88687153abac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import scipy\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "# plt.style.use('dark_background')\n",
    "\n",
    "from modules import ELBO, direct_estimation\n",
    "from utils import load_sim_data\n",
    "\n",
    "import os\n",
    "import matlab.engine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb365d02-3fb2-4d30-a069-cff6f6f42ae5",
   "metadata": {},
   "source": [
    "### Setup parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b5d29512-4b0b-46d2-8453-f0d130172e60",
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 5\n",
    "sim_curvature = 20 # simulated average curvature (in degrees)\n",
    "\n",
    "# whether to load stored data or simulate data by calling the simulation_py.mat function directly\n",
    "load_from_matlab = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "50154107-bb28-40d5-8591-4745f6fc19e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '/Users/nguyentiendung/GitHub/perceptual-straightening/data/simulations/'\n",
    "sim_path = '/Users/nguyentiendung/GitHub/perceptual-straightening/simulations/'\n",
    "out_dict = '/Users/nguyentiendung/GitHub/perceptual-straightening/model/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "363875d3-92ba-4a35-ae98-f85c405b348b",
   "metadata": {},
   "source": [
    "### Run direct estimation algorithm (Maximum Likelihood) to initialize posterior probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7ee7b735-27ea-443c-98ff-eaa54e4d2e3a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trajectory: 0\n"
     ]
    }
   ],
   "source": [
    "c_est, c_true, c, d, a = direct_estimation(sim_path, n_traj=1, n_frames=N, n_dim=N-1, n_iterations=1000, sim_curvature=sim_curvature)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "12ed6d86-60ac-4da8-be86-08dc10d3d152",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create initial values\n",
    "# d_post_init = d.squeeze() + torch.randn(d.squeeze().size())\n",
    "d_post_init = d.squeeze()\n",
    "\n",
    "c_post_init = torch.zeros(N-1)\n",
    "c_post_init[1:] = c.squeeze() \n",
    "c_post_init[0] = torch.mean(c)\n",
    "# c_post_init += torch.randn(c_post_init.size()) * 0.1\n",
    "# c_post_init = torch.zeros(1, N-1)\n",
    "# c_post_init[:, 1:] = c \n",
    "# c_post_init[:, 0] = torch.mean(c)\n",
    "# c_post_init += torch.randn(c_post_init.size()) * 0.1\n",
    "# U, S, _ = torch.linalg.svd(torch.cov(c_post_init.t() @ c_post_init))\n",
    "# c_post_init = U @ torch.diag(torch.sqrt(S))[0,:].squeeze()\n",
    "# c_post_init = c.squeeze() \n",
    "# c_post_init += torch.randn(c_post_init.size()) * 0.1\n",
    "\n",
    "a_post_init = torch.zeros(N-1, N-1)\n",
    "a_post_init[1:] = a.squeeze()\n",
    "a_post_init[0] = torch.mean(a.squeeze(), dim=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fcf5ef5-a00b-40ce-b699-e192637563c5",
   "metadata": {},
   "source": [
    "### Run inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c94fe376-8595-4ac0-b5b8-44b5d77c400d",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 1e-6\n",
    "sim_traj = 1 # number of trajectories to simulate (recovery analysis)\n",
    "# model = ELBO(N, d_post_init, c_post_init, eps=eps)\n",
    "model = ELBO(N, d_post_init, c_post_init, a_post_init, eps=eps)\n",
    "\n",
    "lr = 1e-4\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=lr)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
    "# model_file = Path(out_dict) / f'model_{sim_curvature}.pt'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3635fc2a-ae76-4310-9072-7598e93a03f9",
   "metadata": {},
   "source": [
    "#### Load behavioral data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "16860586-59b8-4002-80a5-3310d923727b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully generated data from MATLAB script.\n"
     ]
    }
   ],
   "source": [
    " # load trial information\n",
    "if load_from_matlab:\n",
    "    os.chdir(sim_path)\n",
    "\n",
    "    # start MATLAB engine\n",
    "    eng = matlab.engine.start_matlab()\n",
    "    ExpParam, Data, Pc_reshaped = eng.simulation_py(sim_curvature, N, N-1, nargout=3)\n",
    "\n",
    "    # stop MATLAB engine\n",
    "    eng.quit()\n",
    "\n",
    "    # extract data matrices\n",
    "    trial_mat = torch.tensor(Data['resp_mat'])\n",
    "    pair_inds = torch.tensor(ExpParam['all_pairs'])\n",
    "    print('Successfully generated data from MATLAB script.')\n",
    "\n",
    "else:\n",
    "    trial_mat = torch.from_numpy(scipy.io.loadmat(Path(data_path) / 'Data.mat')['Data']['resp_mat'][0][0]) \n",
    "    pair_inds = torch.from_numpy(scipy.io.loadmat(Path(data_path) / 'ExpParam.mat')['ExpParam']['all_pairs'][0][0]) \n",
    "    print('Successfully loaded data.')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63e7fd2d-3141-413c-96eb-f5649aedb42a",
   "metadata": {},
   "source": [
    "#### Optimize the whole ELBO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0f4120-dde2-4686-8650-9ec9b310adde",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 291.3607177734375\n",
      "Epoch: 250, Loss: 275.2551574707031\n",
      "Epoch: 500, Loss: 262.4892272949219\n",
      "Epoch: 750, Loss: 251.78846740722656\n",
      "Epoch: 1000, Loss: 242.83299255371094\n",
      "Epoch: 1250, Loss: 235.63848876953125\n",
      "Epoch: 1500, Loss: 229.38528442382812\n",
      "Epoch: 1750, Loss: 223.67727661132812\n",
      "Epoch: 2000, Loss: 218.40280151367188\n",
      "Epoch: 2250, Loss: 213.4291534423828\n",
      "Epoch: 2500, Loss: 208.5560760498047\n",
      "Epoch: 2750, Loss: 202.69415283203125\n",
      "Epoch: 3000, Loss: 188.5521697998047\n",
      "Epoch: 3250, Loss: 185.58413696289062\n",
      "Epoch: 3500, Loss: 182.68551635742188\n",
      "Epoch: 3750, Loss: 179.8186492919922\n",
      "Epoch: 4000, Loss: 176.9599151611328\n",
      "Epoch: 4250, Loss: 174.11514282226562\n",
      "Epoch: 4500, Loss: 171.27322387695312\n",
      "Epoch: 4750, Loss: 168.41976928710938\n",
      "Epoch: 5000, Loss: 165.53807067871094\n",
      "Epoch: 5250, Loss: 162.62867736816406\n",
      "Epoch: 5500, Loss: 159.66929626464844\n",
      "Epoch: 5750, Loss: 156.63267517089844\n",
      "Epoch: 6000, Loss: 153.4989776611328\n",
      "Epoch: 6250, Loss: 150.20928955078125\n",
      "Epoch: 6500, Loss: 146.69091796875\n",
      "Epoch: 6750, Loss: 142.84701538085938\n",
      "Epoch: 7000, Loss: 138.5017852783203\n",
      "Epoch: 7250, Loss: 133.33143615722656\n",
      "Epoch: 7500, Loss: 126.62700653076172\n",
      "Epoch: 7750, Loss: 116.17436218261719\n",
      "Epoch: 8000, Loss: 69.33551025390625\n",
      "Epoch: 8250, Loss: 43.507652282714844\n",
      "Epoch: 8500, Loss: 42.95541000366211\n",
      "Epoch: 8750, Loss: 42.42029571533203\n",
      "Epoch: 9000, Loss: 41.89485549926758\n",
      "Epoch: 9250, Loss: 41.37169647216797\n",
      "Epoch: 9500, Loss: 40.8442497253418\n",
      "Epoch: 9750, Loss: 40.309120178222656\n",
      "Epoch: 10000, Loss: 39.76096725463867\n",
      "Epoch: 10250, Loss: 39.20090866088867\n",
      "Epoch: 10500, Loss: 38.62661361694336\n",
      "Epoch: 10750, Loss: 38.034297943115234\n",
      "Epoch: 11000, Loss: 37.42414855957031\n",
      "Epoch: 11250, Loss: 36.787445068359375\n",
      "Epoch: 11500, Loss: 36.10618591308594\n",
      "Epoch: 11750, Loss: 35.35770797729492\n",
      "Epoch: 12000, Loss: 34.501747131347656\n",
      "Epoch: 12250, Loss: 33.461700439453125\n",
      "Epoch: 12500, Loss: 32.062049865722656\n",
      "Epoch: 12750, Loss: 29.679536819458008\n",
      "Epoch: 13000, Loss: 16.51150131225586\n",
      "Epoch: 13250, Loss: 16.459789276123047\n",
      "Epoch: 13500, Loss: 16.423847198486328\n",
      "Epoch: 13750, Loss: 16.39129066467285\n",
      "Epoch: 14000, Loss: 16.361934661865234\n",
      "Epoch: 14250, Loss: 16.33287239074707\n",
      "Epoch: 14500, Loss: 16.30475616455078\n",
      "Epoch: 14750, Loss: 16.283323287963867\n",
      "Epoch: 15000, Loss: 16.263198852539062\n",
      "Epoch: 15250, Loss: 16.245147705078125\n",
      "Epoch: 15500, Loss: 16.231679916381836\n",
      "Epoch: 15750, Loss: 16.214487075805664\n",
      "Epoch: 16000, Loss: 16.20320701599121\n",
      "Epoch: 16250, Loss: 16.19249725341797\n",
      "Epoch: 16500, Loss: 16.182018280029297\n",
      "Epoch: 16750, Loss: 16.173917770385742\n",
      "Epoch: 17000, Loss: 16.16819190979004\n",
      "Epoch: 17250, Loss: 16.162715911865234\n",
      "Epoch: 17500, Loss: 16.159963607788086\n",
      "Epoch: 17750, Loss: 16.15625\n",
      "Epoch: 18000, Loss: 16.154922485351562\n",
      "Epoch: 18250, Loss: 16.15304183959961\n",
      "Epoch: 18500, Loss: 16.14966583251953\n",
      "Epoch: 18750, Loss: 16.149717330932617\n",
      "Epoch: 19000, Loss: 16.14950942993164\n",
      "Epoch: 19250, Loss: 16.14924430847168\n",
      "Epoch: 19500, Loss: 16.148401260375977\n"
     ]
    }
   ],
   "source": [
    "iterations = 20000\n",
    "\n",
    "# errors\n",
    "errors = np.zeros(iterations)\n",
    "kl_loss = np.zeros(iterations)\n",
    "ll_loss = np.zeros(iterations)\n",
    "\n",
    "# variables\n",
    "c_prior = np.zeros(iterations)\n",
    "d_prior = np.zeros(iterations)\n",
    "c_post = np.zeros((N-1, iterations))\n",
    "# c_post = np.zeros((N-2, iterations))\n",
    "\n",
    "best_iteration = 0\n",
    "for i in range(iterations):\n",
    "    log_ll, d, c, a = model.compute_likelihood(trial_mat, pair_inds, n_samples=100)\n",
    "    kl = model.kl_divergence()\n",
    "    loss = model.compute_loss(log_ll, kl)\n",
    "\n",
    "    # gradient update\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # store errors for each iteration\n",
    "    errors[i] = loss.item()\n",
    "    kl_loss[i] = kl.item()\n",
    "    ll_loss[i] = log_ll.item()\n",
    "    c_prior[i] = model.mu_prior_c.detach().numpy()[0] * (180 / np.pi)\n",
    "    d_prior[i] = model.mu_prior_d.detach().numpy()[0]\n",
    "    c_post[:, i] = model.mu_post_c.detach().numpy() * (180 / np.pi)\n",
    "\n",
    "    # print progress\n",
    "    if not i % 250:\n",
    "        print(f\"Epoch: {i}, Loss: {loss.item()}\")\n",
    "\n",
    "# # save parameters\n",
    "# phi_params = {'d': d_best,\n",
    "#               'c': c_best,\n",
    "#               'a': a_best}\n",
    "# torch.save(phi_params, Path(data_path) / f'params_{sim_curvature}.pt')\n",
    "# torch.save(model.state_dict(), model_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b20ac52-1741-4848-840d-5b436b6c53bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for name, param in model.named_parameters():\n",
    "#     print(f\"{name}: is_leaf={param.is_leaf}, requires_grad={param.requires_grad}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa08416b-3d6d-45cd-9350-4c7dae8d2745",
   "metadata": {},
   "source": [
    "#### Load final model and plot error curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72c7d23c-88e0-476a-ad8a-81b81cc38dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# best_model = ELBO(N, data_path, eps)\n",
    "# best_model.load_state_dict(torch.load(model_file, weights_only=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f26a4df0-b90e-43aa-b8c9-e608bf69dbf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "# Primary y-axis (ELBO and Neg. log likelihood)\n",
    "axs[0].plot(errors, label='ELBO')\n",
    "axs[0].plot(ll_loss, label='Log likelihood')\n",
    "axs[0].set_xlabel('Iteration')\n",
    "axs[0].set_ylabel('Log likelihood')\n",
    "# axs[0].set_yscale('log')\n",
    "# axs[0].tick_params(axis='y')\n",
    "\n",
    "axs[1].plot(kl_loss, label='KL', color='green')\n",
    "axs[1].set_ylabel('KL Loss')\n",
    "# axs[1].tick_params(axis='y')\n",
    "# axs[1].set_yscale('log')\n",
    "\n",
    "# Add legends for both axes\n",
    "axs[0].legend()\n",
    "axs[1].legend()\n",
    "\n",
    "# save and show the plot\n",
    "fig.suptitle('Loss over iterations')\n",
    "plt.savefig(Path(out_dict) / f\"error_{sim_curvature}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37d837e5-0d48-4a4b-ba22-0ca8cf2a1600",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "axs[0].plot(c_prior, label=r'$\\mu_c$')\n",
    "axs[0].set_ylabel(r'$\\mu_{c}$ (degrees)')\n",
    "\n",
    "axs[1].plot(d_prior, label=r'$\\mu_d$')\n",
    "axs[1].set_ylabel(r'$\\mu_{d}$')\n",
    "\n",
    "for i in range(2):\n",
    "    axs[i].legend()\n",
    "    axs[i].set_xlabel('Iteration')\n",
    "\n",
    "fig.suptitle('Parameter learning over iterations (prior)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d491eb1c-27c7-4359-91c4-78792bfbed7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "for i in range(N-2):\n",
    "# for i in range(N-1):\n",
    "    plt.plot(c_post[i])\n",
    "plt.title(r\"Learning of $\\mu_{c_t}$ (posterior)\")\n",
    "plt.ylabel(r'$\\mu_{c_t}$ (degrees)')\n",
    "plt.xlabel(\"Iteration\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b5f1a00-dad4-45dc-a2a9-47f5e0aa4cfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.plot(c_post[6])\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7ac8f7f-5c58-423b-9784-3a1925f8c62f",
   "metadata": {},
   "source": [
    "### Reconstruct trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03960c92-63cd-46bf-ae02-ecf99e301fcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# est_global_curvature = best_model.mu_c.detach().numpy() * (180 / np.pi)\n",
    "est_global_curvature = model.mu_prior_c.detach().numpy() * (180 / np.pi)\n",
    "print(f'Estimated global curvature: {est_global_curvature[0]} degrees')\n",
    "# print(f'Average estimated local curvature: {torch.mean(c_best).detach().numpy() * (180/np.pi)} degrees')\n",
    "print(f'Average estimated local curvature: {torch.mean(c).detach().numpy() * (180/np.pi)} degrees')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2678bc28-3b13-45f3-8b9f-3b72c8be7033",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_pca(X, n_components=2):\n",
    "    \"\"\"\n",
    "    Run PCA on the estimated trajectory. \n",
    "\n",
    "    Inputs:\n",
    "    -------\n",
    "    X: (n_dimensions x n_frames) torch tensor\n",
    "        Input matrix (estimated trajectory)\n",
    "    n_components: Scalar\n",
    "        Number of fitted principle components\n",
    "\n",
    "    Output:\n",
    "    -------\n",
    "    X_new: (n_frames x n_components) numpy array\n",
    "        Transformed values\n",
    "    \"\"\"\n",
    "    \n",
    "    pca = PCA(n_components)\n",
    "    pca.fit(X)\n",
    "    return pca.components_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc32cda-010b-47bc-b118-efd07af59219",
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_from_matlab:\n",
    "    # plot data\n",
    "    ax = sns.heatmap(Pc_reshaped, cmap='Blues')\n",
    "    ax.invert_yaxis()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "634823c5-ce4b-4a90-9986-7e3c8f44a541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# run PCA to reduce the dimensionality of the trajectory\n",
    "# x = torch.squeeze(best_model.construct_trajectory(torch.mean(d_best, dim=0, keepdim=True), \n",
    "#                                torch.mean(c_best, dim=0, keepdim=True), \n",
    "#                                torch.mean(a_best, dim=0, keepdim=True)))\n",
    "x = torch.squeeze(model.construct_trajectory(torch.mean(d, dim=0, keepdim=True), \n",
    "                               torch.mean(c, dim=0, keepdim=True), \n",
    "                               torch.mean(a, dim=0, keepdim=True)))\n",
    "\n",
    "pc = run_pca(x.t().detach().numpy())\n",
    "for i in range(pc.shape[1]-1):\n",
    "    plt.plot([pc[0, i], pc[0, i+1]], [pc[1, i], pc[1, i+1]], '-o')\n",
    "plt.title('Reconstructed perceptual trajectory in PC space')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8323fde0-7aa0-4d29-987f-3a3ddb882b77",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_np = x.detach().numpy().T\n",
    "fig = plt.figure()\n",
    "if N-1 == 2:\n",
    "    # visualize the perceptual trajectory for 2d \n",
    "    ax = fig.add_subplot(111)\n",
    "    for i in range(x.shape[1]-1):\n",
    "        plt.plot([x_np[0, i], x_np[0, i+1]], \n",
    "                 [x_np[1, i], x_np[1, i+1]],)\n",
    "    plt.title('Reconstructed perceptual trajectory in 2D')\n",
    "    plt.show()\n",
    "elif N-1 >= 3:\n",
    "    # visualize the perceptual trajectory for >= 3d (plotting first 3 dimensions)\n",
    "    ax = fig.add_subplot(111, projection='3d')\n",
    "    for i in range(x.shape[1]-1):\n",
    "        plt.plot([x_np[0, i], x_np[0, i+1]], \n",
    "                 [x_np[1, i], x_np[1, i+1]],\n",
    "                 [x_np[2, i], x_np[2, i+1]], '-o')\n",
    "    plt.title('Reconstructed perceptual trajectory in 3D')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02d0e253-28a2-4bd1-acb1-33ff21790e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot histograms of trajectory variables\n",
    "# fig, axs = plt.subplots(figsize=(10, 6))\n",
    "# sns.histplot(c_best.detach().numpy() * (180 / np.pi), kde=True, ax=axs)\n",
    "# axs.set_xlabel('Curvature (degrees)')\n",
    "# axs.set_title('Curvature distribution')\n",
    "# plt.show()\n",
    "fig, axs = plt.subplots(figsize=(10, 6))\n",
    "sns.histplot(c.detach().numpy() * (180 / np.pi), kde=True, ax=axs)\n",
    "axs.set_xlabel('Curvature (degrees)')\n",
    "axs.set_title('Curvature distribution')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04c0e867-ce58-4708-8bbd-19b1ce3828d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
